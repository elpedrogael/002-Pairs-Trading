{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c12810",
   "metadata": {},
   "source": [
    "<img style=\"float: right; margin: 5px 5px 20px 20px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/d/db/Logo_ITESO_normal.jpg\" width=\"100px\" height=\"75px\"/>\n",
    "\n",
    "# 002 Pairs Trading\n",
    "\n",
    "### Microstructures and trading systems\n",
    "\n",
    "> **Evelin Ramirez, Pedro Gael Rayas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edcc83c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Este proyecto implementa una estrategia de Pairs Trading basada en el análisis de series temporales cointegradas. La idea central es identificar dos activos financieros que presenten una relación a largo plazo estable, de manera que la combinación lineal de sus precios sea estacionaria. Para ajustar dinámicamente la relación entre ambos activos, se utiliza un Filtro de Kalman implementado desde cero, lo que permite estimar en tiempo real el hedge ratio (razón de cobertura). Las señales de trading se generan cuando el spread (diferencia entre el precio del activo dependiente y el ajustado por el hedge ratio del activo independiente) se desvía significativamente de su media, utilizando umbrales basados en desviaciones estándar. Finalmente, la estrategia se evalúa mediante un proceso de backtesting que simula operaciones en una cuenta de margen con comisiones y un capital inicial definido.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "La creciente competencia en los mercados financieros ha llevado a la búsqueda de estrategias que permitan obtener beneficios a través del arbitraje estadístico. Una de estas estrategias es el Pairs Trading, la cual se basa en la identificación de pares de activos que, a pesar de sufrir fluctuaciones a corto plazo, mantienen una relación estable en el largo plazo.\n",
    "\n",
    "El presente proyecto se enfoca en la implementación de una estrategia de Pairs Trading mediante:\n",
    "\n",
    "* La verificación de cointegración entre los activos, lo que asegura que la combinación lineal de sus precios es estacionaria.\n",
    "* La estimación dinámica del hedge ratio mediante un Filtro de Kalman implementado desde cero, permitiendo ajustar la exposición a cada activo conforme evoluciona el mercado.\n",
    "* La generación de señales de trading a partir de desviaciones significativas del spread respecto a su media, aplicando umbrales de ±1.5 desviaciones estándar para entrar en posición y señales de salida cuando el spread regresa a niveles cercanos a la media.\n",
    "* El backtesting de la estrategia, en el cual se simula la ejecución de operaciones reales considerando un capital inicial de $1,000,000 USD, comisiones de 0.125% y el uso de cuentas de margen.\n",
    "\n",
    "Esta aproximación permite no solo validar la viabilidad de la estrategia en términos históricos, sino también comprender mejor la dinámica del spread y la efectividad del filtro en la adaptación a cambios en la relación entre los activos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef1809",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "La metodología adoptada en este proyecto se puede desglosar en las siguientes etapas:\n",
    "\n",
    "1. **Descarga y Preprocesamiento de Datos:**\n",
    "   - Se obtienen 10 años de datos históricos de los activos seleccionados (por ejemplo, AAPL y MSFT) mediante una fuente confiable.\n",
    "   - Los datos se limpian y se convierten a formatos adecuados (por ejemplo, asegurando que los precios sean numéricos y la fecha esté en formato `datetime`).\n",
    "\n",
    "2. **Verificación de Cointegración:**\n",
    "   - Se realiza un test de cointegración (por ejemplo, el test de Johansen) para determinar si la combinación lineal de los precios de los dos activos es estacionaria.\n",
    "   - Esta etapa es fundamental para justificar que existe una relación a largo plazo entre los activos, lo que respalda la premisa del Pairs Trading.\n",
    "\n",
    "3. **Estimación del Hedge Ratio mediante Filtro de Kalman:**\n",
    "   - Se implementa desde cero un Filtro de Kalman que permite estimar de forma dinámica el hedge ratio, es decir, la proporción en la que se deben combinar los activos para obtener una relación estacionaria.\n",
    "   - El Filtro de Kalman se actualiza de forma recursiva, adaptándose a la evolución de los precios y permitiendo capturar cambios en la relación entre los activos.\n",
    "\n",
    "4. **Cálculo del Spread y Generación de Señales de Trading:**\n",
    "   - Con el hedge ratio estimado, se calcula el spread como la diferencia entre el precio del activo dependiente y el producto del hedge ratio por el precio del activo independiente.\n",
    "   - Se definen umbrales basados en la media y la desviación estándar del spread:\n",
    "     - **Long Signal:** cuando el spread cae por debajo de la media menos 1.5 desviaciones estándar.\n",
    "     - **Short Signal:** cuando el spread supera la media más 1.5 desviaciones estándar.\n",
    "     - **Exit Signal:** cuando el spread regresa a un rango cercano a la media (por ejemplo, dentro de ±0.5 desviaciones estándar).\n",
    "\n",
    "5. **Backtesting de la Estrategia:**\n",
    "   - Se simula la ejecución de operaciones a lo largo del tiempo utilizando las señales generadas, considerando un capital inicial de \\$1,000,000 USD.\n",
    "   - Se modelan las operaciones de apertura y cierre de posiciones, aplicando una comisión del 0.125% en cada transacción y, si es necesario, se simula el uso de cuentas de margen.\n",
    "   - Se registra la evolución del capital (curva de equity) y se calculan métricas de rendimiento que permiten evaluar la efectividad de la estrategia.\n",
    "\n",
    "6. **Visualización y Análisis de Resultados:**\n",
    "   - Se generan gráficos que muestran la evolución del spread, las señales de trading y la curva de capital a lo largo del tiempo.\n",
    "   - Estos gráficos y métricas permiten identificar períodos de alta rentabilidad, drawdowns y la robustez de la estrategia ante cambios en la dinámica de los precios.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18daedb",
   "metadata": {},
   "source": [
    "## Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626a631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import yfinance as yf\n",
    "#import pandas as pd\n",
    "\n",
    "#def download_data(tickers, start_date, end_date):\n",
    " #   data = yf.download(tickers, start=start_date, end=end_date)\n",
    "  #  data.reset_index(inplace=True)  # Asegura que la fecha sea una columna\n",
    "   # data.to_csv('historical_data.csv', index=False)  # Guarda correctamente\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    " #   tickers = ['AAPL', 'MSFT']  # Activos a analizar\n",
    "  #  start_date = '2014-01-01'\n",
    "   # end_date = '2024-01-01'\n",
    "    # download_data(tickers, start_date, end_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb23bc18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Date         0 non-null      float64\n",
      " 1   Adj Close    1 non-null      object \n",
      " 2   Adj Close.1  1 non-null      object \n",
      " 3   Close        1 non-null      object \n",
      " 4   Close.1      1 non-null      object \n",
      " 5   High         1 non-null      object \n",
      " 6   High.1       1 non-null      object \n",
      " 7   Low          1 non-null      object \n",
      " 8   Low.1        1 non-null      object \n",
      " 9   Open         1 non-null      object \n",
      " 10  Open.1       1 non-null      object \n",
      " 11  Volume       1 non-null      object \n",
      " 12  Volume.1     1 non-null      object \n",
      "dtypes: float64(1), object(12)\n",
      "memory usage: 232.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Adj Close.1</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close.1</th>\n",
       "      <th>High</th>\n",
       "      <th>High.1</th>\n",
       "      <th>Low</th>\n",
       "      <th>Low.1</th>\n",
       "      <th>Open</th>\n",
       "      <th>Open.1</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Adj Close, Adj Close.1, Close, Close.1, High, High.1, Low, Low.1, Open, Open.1, Volume, Volume.1]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"historical_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data_info = data.info()\n",
    "data_head = data.head()\n",
    "\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "columns = data.columns\n",
    "\n",
    "data_info, data_head, missing_values, columns\n",
    "\n",
    "#\n",
    "\n",
    "data_cleaned = data.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "numeric_columns = ['Close', 'Close.1', 'High', 'High.1', 'Low', 'Low.1', 'Open', 'Open.1', 'Volume', 'Volume.1']\n",
    "data_cleaned[numeric_columns] = data_cleaned[numeric_columns].astype(float)\n",
    "\n",
    "data_cleaned = data_cleaned.dropna()\n",
    "\n",
    "data_cleaned.head()\n",
    "\n",
    "data_cleaned = data_cleaned.rename(columns={'Price': 'Date'})\n",
    "data_cleaned['Date'] = pd.to_datetime(data_cleaned['Date'])\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37469417",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2894c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from kalman_filter import KalmanFilter\n",
    "\n",
    "def check_cointegration(data):\n",
    "    result = coint_johansen(data, det_order=0, k_ar_diff=1)\n",
    "    return result.lr1[0] > result.cvt[0, 0]  # Check if cointegrated\n",
    "\n",
    "def calculate_hedge_ratio(data):\n",
    "    kf = KalmanFilter()\n",
    "    hedge_ratios = []\n",
    "\n",
    "    for x, y in zip(prices_x, prices_y):\n",
    "        kf.predict()\n",
    "        kf.update(x, y)\n",
    "        hedge_ratios.append(kf.get_hedge_ratio())\n",
    "\n",
    "    return np.array(hedge_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a886e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "- AAPL: No data found for this date range, symbol may be delisted\n",
      "- MSFT: No data found for this date range, symbol may be delisted\n",
      "Datos descargados y guardados en 'historical_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Definir los tickers y el rango de fechas\n",
    "tickers = ['AAPL', 'MSFT']\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "# Descargar los datos históricos con yfinance\n",
    "data_downloaded = yf.download(tickers, start=start_date, end=end_date)\n",
    "\n",
    "# Reiniciar el índice para que la fecha se convierta en una columna\n",
    "data_downloaded.reset_index(inplace=True)\n",
    "\n",
    "# Guardar los datos en un archivo CSV\n",
    "data_downloaded.to_csv(\"historical_data.csv\", index=False)\n",
    "\n",
    "print(\"Datos descargados y guardados en 'historical_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e430246",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AAPL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AAPL'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Asegurar que las columnas de precios sean numéricas\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAAPL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Eliminar filas que tengan NaN en las columnas críticas\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AAPL'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV con los datos históricos\n",
    "# Se asume que \"historical_data.csv\" contiene al menos las columnas: \"Date\", \"AAPL\" y \"MSFT\"\n",
    "data = pd.read_csv(\"historical_data.csv\")\n",
    "\n",
    "# Convertir la columna de fecha a formato datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Asegurar que las columnas de precios sean numéricas\n",
    "data['AAPL'] = pd.to_numeric(data['AAPL'], errors='coerce')\n",
    "data['MSFT'] = pd.to_numeric(data['MSFT'], errors='coerce')\n",
    "\n",
    "# Eliminar filas que tengan NaN en las columnas críticas\n",
    "data = data.dropna(subset=['AAPL', 'MSFT', 'Date'])\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65128da3",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ae99a",
   "metadata": {},
   "source": [
    "## Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0d43f-d366-4d77-9e3d-3b9d83d9165d",
   "metadata": {},
   "source": [
    "## Github\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
